\input{preamble}

\begin{document}

% Title
\maketitle

% Abstract
\section{Abstract}

\textbf{Background}\\
\lipsum[1]
\textbf{Aim}: ...

\textbf{Methods}\\
\lipsum[1]

\textbf{Results}\\
\lipsum[1]

\textbf{Conclusion}\\
\lipsum[1]

\textbf{Keywords: schizophrenia, sMRI, CNN}

% Introduction
\section{Introduction}

Schizophrenia (SZ) is a chronic mental disorder affecting 1 in 300 people worldwide (Harestad, 2024), characterized by disruptions in thought processes, perception, and social functioning. Accurate and timely diagnosis is crucial for effective management, yet schizophrenia remains one of the most challenging disorders to diagnose due to its heterogeneity and overlap with other psychiatric conditions (Joyee et al,; Benlee & Adac). Being linked to structural and functional brain abnormalities, SZ has been actively studied using Magnetic Resonance Imaging (MRI). Structural MRI has contributed to our understanding of the neural basis of SZ, highlighting abnormalities such as ventricular enlargement, gray and white matter alterations, frontal cortex enlargement, and cortical thickness (Joyee et al.; Teskera & Bozek.,2023).

%neuroimaging has emerged as a powerful tool for identifying biomarkers associated with schizophrenia. 

The advent of machine learning (ML) and deep learning (DL) techniques has further accelerated efforts to automate schizophrenia diagnosis by analyzing complex neuroimaging data.

Despite the significant progress in developing convolutional neural network (CNN) architectures for schizophrenia detection [REFS!!!], a critical challenge persists: the lack of standardization in preprocessing and feature extraction pipelines. Variability in preprocessing methods---such as noise removal, intensity normalization, and artifact correction---introduces inconsistencies in model training and evaluation.

Existing literature primarily emphasizes developing DL models, often neglecting to explicitly detail the preprocessing steps applied to the neuroimaging data. This gap is particularly concerning, as preprocessing directly impacts the quality and reliability of input data, influencing downstream analyses and model performance. Studies leveraging benchmark datasets,[REFS!!!] such as BrainGluSchi, COBRE, MCICShare, NMorphCH, and NUSDAST frequently report high classification accuracies, but the preprocessing pipelines remain inadequately documented or inconsistent, further complicating efforts to replicate findings.

%Similarly, differences in feature extraction techniques hinder the interpretability and generalizability of machine learning outputs, as they may target inconsistent brain regions or utilize diverse spatial features. These issues contribute to variability in reported results across studies, limiting reproducibility and comparability.

To address these challenges, this project aims to systematically experiment with various preprocessing techniques commonly used in medical imaging, such as contrast enhancement, noise removal, and data augmentation. By evaluating their impact on schizophrenia detection from MR images, we seek to propose a robust and reproducible preprocessing pipeline. Standardizing preprocessing practices could enhance the reproducibility of ML-based schizophrenia diagnostics, ultimately contributing to more reliable and clinically applicable models.

% Methods
\section{Methods}

\subsection{Dataset and Exploratory Data Analysis}

The raw data were obtained from the \href{http://schizconnect.org}{SchizConnect} database (accessed January 1, 2025), which houses structural and functional MRI data. The database provides filtering options to enable users to select data that meets specific criteria including MRI field strength and clinical diagnosis (e.g. schizophrenia, bipolar disorder).

The data obtained originates from the Center of Biomedical Research Excellence (COBRE) [REF!!!] dataset in NifTI format. It includes data from 62 individuals, 30 with schizophrenia and 32 healthy controls. [CHECK!!!]

The data from SchizConnect was filtered based on MRI field strength and clinical diagnosis. We retrieved only images captured with 3T MRI scans. This was done to ensure uniformity of the data obtained.

Clinical data was made available in form of CSV files. The demographic features of the dataset used in this project are presented in Table~\ref{tab:cobre_mcicshare_clinical_demographic}.
%Figure~\ref{fig:demographic_features} shows the age and gender distribution.

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.4\textwidth]{./figs/demographic_features.png}
%    \caption{Demographic features of the COBRE dataset.}\label%{fig:demographic_features}
%\end{figure}

% Figs should not duplicate the tables and vice versa

\begin{center}
	\begin{table}
        \centering
        \caption{\label{tab:cobre_mcicshare_clinical_demographic}The subjects were selected to give a balanced representation of age and gender distributions in the dataset, prioritizing age distribution, which has been shown to affect model performance (ref).}
        \begin{tabular*}{500pt}{@{\extracolsep\fill}lcccccc@{\extracolsep\fill}}
            \toprule
            & \multicolumn{3}{c}{COBRE}
            \\\cmidrule{2-4}
            & \textbf{Individuals with SZ (n=30)} & \textbf{Healthy controls (n=32)} & \textbf{Total (62)} \\
            \midrule
            Minimum age             & 19  & 18  & 18 \\
            Maximum age 		    & 66  & 65 & 66  \\
            Average age             & 39.6 & 41 & 40.3	\\
            Gender (Male/ Female)   & 19/11 & 17/15 & 36/26	\\
            \bottomrule
        \end{tabular*}
    \end{table}    
\end{center}

%
\subsection{Image Preprocessing}

% General thoughts
The major idea behind preprocessing was to establish a standardized pipeline that ensures consistency in the quality and content of the MRI data. This pipeline addressed common issues such as noise, intensity variations, and artifacts, which can affect the performance of machine learning models.

We experimented with different combinations of preprocessing and data augmentation techniques to determine which pipeline yields the best performance of the ML/DL models regarding recall rate, precision, and F1 score.

In order to find the best combination of hyperparameters for each preprocessing method, we performed a grid search and measured the quality metrics of the processed image using a custom test function.

Table~\ref{tab:preprocessing_pipeline} and Table~\ref{tab:augmentation_pipeline} present the preprocessing and augmentation techniques respectively used and their respective hyperparameters and tools used. Figure~\ref{fig:test_pipeline} gives a visual representation of the conducted tests.
%
\begin{center}
    \begin{table}
        \centering
        \caption{\label{tab:preprocessing_pipeline}Preprocessing techniques used in the study.}
        \begin{tabular*}{500pt}{@{\extracolsep\fill}lcc@{\extracolsep\fill}}
            \toprule
            \textbf{Preprocessing Step} & \textbf{Hyperparameters} & \textbf{Tools} \\
            \midrule
            Resampling & Voxel size: 1mm & Nibabel library \\
            Intensity Normalization & Min-max scaling: [0, 1] & NumPy \\
            Brain Extraction & Modality: T1, U-net & ANTsPyNet \\
            Cropping & Size: based on the largest bounding box among all images & scikit-image, NumPy \\
            Smoothing & Gaussian filter: sigma=1.5 & SciPy \\
            \bottomrule
            \end{tabular*}
    \end{table}
\end{center}

%
\begin{center}
    \begin{table}
        \centering
        \caption{\label{tab:augmentation_pipeline}Augmentation techniques used in the study.}
        \begin{tabular*}{500pt}{@{\extracolsep\fill}lcc@{\extracolsep\fill}}
            \toprule
            \textbf{Augmentation Step} & \textbf{Hyperparameters} & \textbf{Tools} \\
            \midrule
            Rotation & Angle (degrees): 20 & torchvision \\
            Blurring & Sigma: ...  & NumPy \\
            Noise & Noise (std): ... & ANTsPyNet \\
            \bottomrule
            \end{tabular*}
    \end{table}
\end{center}
%
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{./figs/test_pipeline.png}
    \caption{Tests pipeline for MRI data.}\label{fig:test_pipeline}
\end{figure}

\subsubsection{Resampling}

The first step of the pipeline is resampling the image to a standard resolution to ensure uniform input for the model and consistent noise and signal profiles.

\subsubsection{intensity normalization}

The second step of the pipeline is normalization of voxel intensities to a consistent range to maintain the relative scale of the data and produce values in a fixed range to satisfy models expectations. The adopted method scales the data to a range of [0, 1].

Normalization also improves the results of brain extraction by helping the algorithm better distinguish between brain and non-brain regions.

Intensity distributions were inspected to ensure normalization has not distorted the data.

\subsubsection{Brain extraction}

The third step of the pipeline is a brain extraction. The purpose of this stage is to
\begin{itemize}
    \item remove non-brain regions in order to minimizes noise, making it easier for the network to focus on relevant features;
    \item subsequently enhance the network's performance, especially in a schizophrenia detection task where small differences in brain anatomy are crucial;
    \item ensure that the input images are more consistent in terms of content, which can help the model generalize better.
\end{itemize}

The generated brain mask was refined by closing gaps and removing small regions. The mask was also used as a leverage for the cropping step.

% Discuss When Brain Extraction May Not Be Necessary

%The nobrainer tool offers pre-trained deep learning models for brain extraction and is designed for robust performance on diverse datasets.ANTsPyNet is a Python library that offers neural network architectures and pre-trained models for medical image analysis, including brain extraction.

\subsubsection{Cropping}

The fourth step of the pipeline is cropping the brain region to a consistent size across scans.

\subsubsection{Smoothing}

The fifth step of the pipeline is smoothing the brain region to reduce noise and variability introduced by acquisition artifacts, enhancing the overall quality of the images. This was done to ensure that the downstream tasks are more robust and the model training is more effective. We used a Gaussian filter to reduce high-frequency noise while preserving edges to some extent. Since the neural network performed a classification task, moderate smoothing was carried out to focus on broader patterns.

The sixth step of the pipeline is normalization of the smoothed image to ensure that ...

\subsubsection{Validation}

The impact of preprocessing on the data's integrity and quality was assessed using a combination of a visual inspection and quantitative metrics. The visual inspection involved plotting a few slices of the MRI before and after each preprocessing step. Validation was performed to ensure that preprocessing steps did not introduce artifacts or distort anatomical structures, and to ensure consistency of the processed images.

Quantitative metrics included Signal-to-Noise Ratio (SNR), Contrast-to-Noise Ratio (CNR), Peak Signal-to-Noise Ratio (PSNR), and 
Structural Similarity Index (SSIM). 

Relative PSNR for one image. Using a hypothetical "ideal" signal (the maximum intensity value as a baseline), a relative PSNR for one image was calculated. This relative PSNR was used as a way to assess the "quality" of a single image compared to a theoretical perfect image of uniform intensity.

A binary mask was computed using Otsu's thresholding to explicitly select a background region for noise estimation.

The metrics were computed for the entire 3D volume to assess the overall quality or similarity of the entire MRI dataset, capturing global differences.

% Discuss Metrics for Each 2D Slice (Slice-wise Approach):

%
\subsection{Data Augmentation}

1st Method In this method, a shearing angle, which is selected randomly within the range [− 15°, 15°], is used and a shearing operation is applied within the x and y-axis. This operation is repeated 10 times with 10 different shearing angles. By this method, 10 images are generated from an original image.

3rd Method Rotation angles are selected randomly within the range [− 25°, 25°] and clockwise rotations are applied using 10 different angle values. 10 images are generated from an original image by this method.

7th Method In this method, augmentation is provided by Gaussian noise addition (4th method) followed by rotation (3rd method). 30 images are generated from an input image by this method

8th Method In this augmentation method, clockwise rotation and then translation operations are applied. Rotation angles are selected randomly within the range [− 25°, 25°] and translation is applied on the x and y-axis by using different values sampled randomly within the range [− 15, 15]. This successive operation is applied 10 times, and 10 images are generated from an input image by this method.

9th Method In this method, translation is applied followed by the shearing. The translation step is applied on the x and y-axis with different values sampled randomly within the range [− 15, 15]. In the shearing step, an angle is selected randomly within the range [− 15°, 15°], and shearing is applied within the x and y-axis. The subsequent operations are applied 10 times and 10 images are generated from an input image by this method.

10th Method In this method, three operations (translation, shearing, and rotation) are applied subsequently. Implementation of the translation and shearing operations are performed as explained in the 9th method. In the rotation step, a random angle is selected within the range [− 25°, 25°] clockwise rotation is applied. The successive operations are applied 10 times, and 10 images are generated from an input image by this method.




Here are some common transformations you can apply to your MRI images, tailored to medical imaging:
a. Flips
Horizontal Flip (RandomHorizontalFlip): Good for brain MRI images, as the brain is symmetric along the sagittal plane.
Vertical Flip (RandomVerticalFlip): Less commonly used, but still possible, depending on the orientation of your images.
b. Rotations
RandomRotation: Useful for handling minor variations in patient positioning during scans.
Angle Range: Typically, 10°–30° is sufficient. Avoid large angles (>45°), as they may produce unrealistic data.

c. Random Affine Transform
Includes translation, scaling, rotation, and shear.
Translation: Small translations (e.g., up to 10% of image size) simulate minor misalignments.
Scaling: Scale variations between 0.9x and 1.1x are typical.
Shear: Small shearing angles (e.g., ±10°) can add variety.
d. Intensity-Based Augmentations
RandomBrightness or RandomGamma: Simulates variations in scan intensity due to different machines or settings.
Gaussian Noise: Adds noise to simulate variations or imperfections in the imaging process.

f. Cropping and Resizing
Center cropping or random cropping to extract relevant parts of the brain.
Resize all images to a fixed size (e.g., (128, 128, 128) or (256, 256, 256)) for consistency.

Brightness and Contrast: Adjusting these properties can simulate variations in scanner settings, but it must be done carefully. Too much adjustment may distort the structural information critical for your task.

For MRI images, adding noise or slight intensity shifts is a more domain-specific way to introduce variation:


2. Choosing Parameters
The parameters depend on your dataset and the expected variations in real-world data:

Domain Knowledge: Consult with radiologists or domain experts to understand typical variations in brain MRI scans.
Visualize Transformed Data: Plot augmented samples to ensure the transformations don't distort anatomical features.
Experimentation: Start with conservative parameters (e.g., small rotations, flips) and gradually expand based on model performance.

4. Validation Images
No Augmentation: Do not apply augmentation to validation or test images. Simply normalize and resize them for consistency:

%
\subsection{Model architectures}

Convolutional Neural Networks (CNNs) are commonly used in the literature for this task [REFS!!]. However, a few papers explored the use of support vector machines for image classification [REFS!!]. To gain a full understanding of both approaches, we decided on the combination of a pretrained deep neural network for feature extraction and a support vector classifier for binary classification. The ReNet-18 architecture was selected for its balance between computational load and accuracy. Cross validation was performed with the support vector classifier to choose the best hyperparameters, and the hyperparameters that yielded the best results were the radial basis function (RBF) kernel, a gamma value of 0.0001 and a C parameter value of 100. Each 2D slice of the images were fed into the ResNet-18 model as NumPy arrays of dimension 224 ✕ 224. This input size corresponds to the size of the images in the ImageNet dataset that was used to train ResNet-18 and was selected for compatibility with the pretrained weights of the ResNet-18 model. Figure~\ref{fig:training_architecture} gives a representation of the training architecture and flow.
%
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{./figs/training_architecture.png}
    \caption{Training architecture and flow.}\label{fig:training_architecture}
\end{figure}

%
\subsection{CNN validation}

% Results
\section{Results}

\subsection{Image Preprocessing}

An SNR greater than 1 means that the average signal is more intense than the noise.

MRI SNR Values
For MRI, typical SNR values in literature are often much higher than 1:
Clinical MRIs: SNR values between 10–40 for good-quality scans.
Research MRIs: Values can exceed 50 or even 100 in highly optimized settings.
Values below 10 may indicate noisy or poor-quality scans.

PSNR Behavior:
PSNR should be higher when the image quality is better, which typically results in a greater difference between the actual data and the ideal reference.
If you have well-normalized data and a clean signal with little noise, PSNR will naturally be higher because it’s measuring how close the data is to an ideal version of the image.
Expected Value Ranges:
SNR values typically range between 10 and 40 for good quality MRI images.
PSNR values, when properly calculated, can be much higher because they consider an ideal signal. For instance, PSNR values between 20 and 50 dB are common, but they depend heavily on image resolution, noise, and contrast.

How to Interpret These Results:
SNR = 100: Indicates that the image has a strong signal relative to noise. This is expected after smoothing because smoothing reduces noise.
PSNR = 45: Indicates that the smoothed image differs moderately from the original. This suggests the smoothing process significantly altered the pixel intensities.

\subsection{Data Augmentation}

\subsection{CNN performance}

% Random text
\lipsum[5-6]

% Discussion
\section{Discussion}

The methods used for brain MR image augmentation have some limitations or drawbacks. For instance, in a study (Isensee et al. 2020), the augmentation approach uses elastic deformations, which add shape variations. However, the deformations can bring lots of damage and noise when the deformation field is varied seriously. Also, the generated images seem not to be realistic and natural. It has been shown in the literature that widely used elastic deformations produce unrealistic brain MR images (Mok and Chung 2018).

augmentation with the combination of shearing and salt-and-pepper noise addition is the least efficient approach for augmentation in improving classification performance 

% Conclusion
\section{Conclusion}

% Random text
\lipsum[9-10]



% Formalities
\section*{Acknowledgements}

...

\subsection*{Author contributions}

\textbf{Conception}: Prosperity Oguama, Ilia Golub; \textbf{Data Acquisition}: Ilia Golub; \textbf{Preprocessing Pipeline Development}: ...; \textbf{Preprocessing Pipeline Testing}: ...; \textbf{Data Augmentation Pipeline Testing}: ...; \textbf{Neural Network Building}: ...; \textbf{Neural Network Testing}: ...; \textbf{Drafting \& Editing}: Ilia Golub, Prosperity Oguama. All authors contributed to the study, read, revised and approved the final manuscript.

\subsection*{Data availability statement}
The data underlying this article is publicly available and accessible through \hyperlink{Schizconnect}{http://schizconnect.org/}.

\subsection*{Financial disclosure}

The authors report no financial disclosure.

\subsection*{Conflict of interest}

The authors declare no potential conflict of interests.

\end{document}